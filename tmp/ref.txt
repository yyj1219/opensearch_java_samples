import jakarta.json.Json;
import org.opensearch.client.json.JsonData;
import org.opensearch.client.opensearch.OpenSearchClient;
import org.opensearch.client.opensearch._types.*;
import org.opensearch.client.opensearch._types.aggregations.*;
import org.opensearch.client.opensearch._types.query_dsl.*;
import org.opensearch.client.opensearch.core.SearchRequest;
import org.opensearch.client.opensearch.core.SearchResponse;
import org.opensearch.client.opensearch.core.search.Hit;
import org.opensearch.client.opensearch.core.search.SourceConfig;
import org.opensearch.client.opensearch.generic.OpenSearchClientException;
import scouter.db.elastic.metering.XLogHistoMetering;
import scouter.db.elastic.vo.HeatMapBucket;
import scouter.db.elastic.vo.XLogHistoVo;
import scouter.lang.TextTypes;
import scouter.lang.args.TopTxSearchArgs;
import scouter.lang.args.XLogInfoSearchArgs;
import scouter.lang.counters.E2ETypeConstants;
import scouter.server.Logger;
import scouter.server.util.QueryUtil;
import scouter.util.DateUtil;
import scouter.config.CommonConfigure;
import tuna.server.db.common.TextSearchHelper;
import tuna.server.db.common.TextSearchInfo;
import tuna.server.db.common.opensearch.OpenSearchConnectionManager;
import tuna.server.db.common.opensearch.OpenSearchUtil;
import tuna.server.db.rd.IEndUserTxRD;
import tuna.server.db.rd.factory.TextRDFactory;
import tuna.server.db.rd.opensearch.TextOschRD;
import tuna.server.text.cache.LocalTextCache;
import java.io.IOException;
import java.time.ZoneId;
import java.util.*;
import java.util.function.Consumer;
import java.util.stream.Collectors;

public class EndUserTxOschRD implements IEndUserTxRD {
    private final CommonConfigure conf;
    private final int XLOG_HISTO_TIME_BUCKETS = 150;
    private final TextSearchHelper textSearchHelper;

    public EndUserTxOschRD() {
        this.textSearchHelper = TextSearchHelper.getInstance();
        this.conf = CommonConfigure.getInstance();
    }

    //  EndUser Xlog 전체를 가져오는 Method
    //  Scroll 을 이용해 전체 데이터를 가져옴
    //  2019.07.22  최대 1,000 건만 조회하도록 변경된 LoadEndUserXLogInfo 를 사용함
    //  추후 전체데이터를 요청할 경우에 대비하여 Method를 남겨두고 Deprecate 함
    @Override
    public List<Map<String, Object>> LoadEndUserXLogInfo(XLogInfoSearchArgs args) {
        try {
            List<String> timeList = DateUtil.getSearchRangeTime("enduser-info-", args.from, args.to);
            if (timeList == null) return null;

            String[] indexes = timeList.toArray(new String[0]);

            List<Query> filterQueryList = new ArrayList<>();
            List<Query> mustNotQueryList = new ArrayList<>();

            filterQueryList.add(
                    RangeQuery.of(r -> r
                            .field("endTime")
                            .gte(JsonData.of(args.from))
                            .lte(JsonData.of(args.to))
                    ).toQuery()
            );
            filterQueryList.add(
                    RangeQuery.of(r -> r
                            .field("elapsedTime")
                            .gte(JsonData.of(args.fromElapsed))
                            .lte(JsonData.of(args.toElapsed))
                    ).toQuery()
            );
            filterQueryList.add(
                    TermsQuery.of(t -> t
                            .field("objHash")
                            .terms(v -> v.value(OpenSearchUtil.getFieldValueList(args.objList)))
                    ).toQuery()
            );

            if (args.serviceHash != 0L) {
                filterQueryList.add(
                        MatchQuery.of(m -> m
                                .field("serviceHash")
                                .query(FieldValue.of(args.serviceHash))
                        ).toQuery()
                );
            }
            mustNotQueryList.add(
                    MatchQuery.of(m -> m
                            .field("type")
                            .query(FieldValue.of(E2ETypeConstants.ERROR))
                    ).toQuery()
            );

            Map<String, Object> filters = args.fileterMap;
            for (String key : filters.keySet()) {
                if (key.equals("elapsed")) {
                    filterQueryList.add(
                            RangeQuery.of(r -> r
                                    .field("elapsedTime")
                                    .gte(JsonData.of(filters.get(key)))
                            ).toQuery()
                    );
                } else if (key.equals("error")) {
                    mustNotQueryList.add(
                            MatchQuery.of(m -> m
                                    .field("errorHash")
                                    .query(FieldValue.of(0))
                            ).toQuery()
                    );
                } else {
                    TermsQuery.of(t -> t
                            .field(key)
                            .terms(tqf -> tqf.value(OpenSearchUtil.getFieldValueList(filters.get(key))))
                    ).toQuery();
                }
            }

            String order = args.order != null && !args.order.equals("") ? args.order : "elapsedTime";
            SortOrder orderCmd = args.orderCmd != null && args.orderCmd.equals("asc") ? SortOrder.Asc : SortOrder.Desc;

            List<String> docValueFieldList = Arrays.asList(
                    "domProcessingTime", "elapsedTime", "endTime", "errorHash", "networkTime", "objHash",
                    "objName", "serverTime", "serviceHash", "timeToDomComplete", "timeToDomInteracitve",
                    "loadTime", "connectionTime", "sslConnectionTime", "dnsLookupTime", "timeToFirstByteRecv",
                    "type", "userIp", "gxid", "agentHash", "pageProcessingTime", "os", "browser", "uuid");
            ArrayList<FieldAndFormat> docValueFields = new ArrayList<>();
            for (String docValueField: docValueFieldList) {
                docValueFields.add(FieldAndFormat.of(f -> f.field(docValueField)));
            }
            SearchRequest request = new SearchRequest.Builder()
                    .index(Arrays.asList(indexes))
                    .size(conf.es_query_fetch_size)
                    .sort(s -> s.field(f -> f.field(order).order(orderCmd)))
                    .query(Query.of(q -> q.bool(bool -> bool.filter(filterQueryList).mustNot(mustNotQueryList))))
                    .source(SourceConfig.of(sc -> sc.fetch(false)))
                    .docvalueFields(docValueFields)
                    .ignoreUnavailable(true)
                    .allowNoIndices(true)
                    .expandWildcards(ExpandWildcard.Open)
                    .build();

            if (conf.print_es_query) {
                OpenSearchUtil.printJson(request);
            }

            OpenSearchClient client = Objects.requireNonNull(OpenSearchConnectionManager.getInstance()).getReadClient();
            SearchResponse<Map> response = client.search(request, Map.class);
            List<Map<String, Object>> resultList = new ArrayList<>();
            for (Hit<Map> hit : response.hits().hits()) {
                Map<String, Object> valueMap = new HashMap<>();
                for (Map.Entry<String, JsonData> field : Objects.requireNonNull(hit.fields()).entrySet()) {
                    String fieldName = field.getKey();
                    switch (fieldName) {
                        case "endTime":
                            valueMap.put("endTime", Long.parseLong(field.getValue().toString()));
                            break;
                        case "serviceHash":
                            int serviceHash = Integer.parseInt(field.getValue().toString());
                            valueMap.put(fieldName, serviceHash);
                            valueMap.put("service", textSearchHelper.searchText(new TextSearchInfo(), TextTypes.SERVICE, serviceHash));
                            break;
                        case "errorHash":
                            int errorHash = Integer.parseInt(field.getValue().toString());
                            valueMap.put("error", errorHash);
                            valueMap.put("errorMsg", textSearchHelper.searchText(new TextSearchInfo(), TextTypes.ERROR, errorHash));
                            break;
                        default:
                            valueMap.put(fieldName, field.getValue());
                            break;
                    }
                }
                long endTime = Long.parseLong(valueMap.get("endTime").toString());
                int elapsed = Integer.parseInt(valueMap.get("elapsedTime").toString());
                valueMap.put("startTime", endTime - elapsed);
                resultList.add(valueMap);
            }

            LocalTextCache localTextCache = null;
            TextSearchInfo textSearchInfo = new TextSearchInfo();
            if (textSearchInfo.getSize() > 0) {
                localTextCache = TextOschRD.getInstance().getString(textSearchInfo);
                if (localTextCache != null) {
                    for (Map<String, Object> map : resultList) {
                        if (map.get("serviceHash") != null && map.get("service") == null) {
                            map.put("service", localTextCache.get(TextTypes.SERVICE, Integer.parseInt(map.get("serviceHash").toString())));
                        }
                        if (map.get("error") != null && map.get("errorMsg") == null) {
                            map.put("errorMsg", localTextCache.get(TextTypes.ERROR, Integer.parseInt(map.get("error").toString())));
                        }
                    }
                }
            }
            if (conf.print_es_query_result) {
                QueryUtil.print(resultList);
            }
            return resultList;
        } catch (Exception e) {
            Logger.println(e);
            return null;
        }
    }

    public Map<String, Object> LoadEndUserXLogHistogram(XLogInfoSearchArgs args) throws Exception {
        try {
            List<String> timeList = DateUtil.getSearchRangeTime("enduser-info-", args.from, args.to);
            if (timeList == null) return null;

            String[] indexes = timeList.toArray(new String[0]);

            List<Query> filterQueryList = new ArrayList<>();
            List<Query> mustNotQueryList = new ArrayList<>();

            filterQueryList.add(
                    RangeQuery.of(r -> r
                            .field("endTime")
                            .gte(JsonData.of(args.from))
                            .lte(JsonData.of(args.to))
                    ).toQuery()
            );
            filterQueryList.add(
                    TermsQuery.of(t -> t
                            .field("objHash")
                            .terms(v -> v.value(OpenSearchUtil.getFieldValueList(args.objList)))
                    ).toQuery()
            );

            Map<String, Object> filters = args.fileterMap;
            for (String key : filters.keySet()) {
                if (key.equals("elapsed")) {
                    filterQueryList.add(
                            RangeQuery.of(r -> r
                                    .field("elapsedTime")
                                    .gte(JsonData.of(filters.get(key)))
                            ).toQuery()
                    );
                } else if (key.equals("error")) {
                    mustNotQueryList.add(
                            MatchQuery.of(m -> m
                                    .field("errorHash")
                                    .query(FieldValue.of(0))
                            ).toQuery()
                    );
                } else {
                    TermsQuery.of(t -> t
                            .field(key)
                            .terms(tqf -> tqf.value(OpenSearchUtil.getFieldValueList(filters.get(key))))
                    ).toQuery();
                }
            }

            if (args.serviceHash != 0L) {
                filterQueryList.add(
                        MatchQuery.of(m -> m
                                .field("serviceHash")
                                .query(FieldValue.of(args.serviceHash))
                        ).toQuery()
                );
            }
            mustNotQueryList.add(
                    MatchQuery.of(m -> m
                            .field("type")
                            .query(FieldValue.of(E2ETypeConstants.ERROR))
                    ).toQuery()
            );

            long searchInterval = args.to - args.from;
            long histogramTimeInterval = searchInterval / this.XLOG_HISTO_TIME_BUCKETS;
            Logger.println("histogramTimeInterval : " + histogramTimeInterval);

            // set histogram unit : time, elapsed
            List<Map<String, CompositeAggregationSource>> compSources = List.of(
                    Map.of("time",
                            CompositeAggregationSource.of(s -> s
                                    .histogram(h -> h
                                            .field("endTime")
                                            .interval((double) histogramTimeInterval)
                                    )
                            )
                    ),
                    Map.of("elapsed",
                            CompositeAggregationSource.of(s -> s
                                    .histogram(h -> h
                                            .field("elapsedTime")
                                            .interval((double) conf.xlog_hist_elapsed_interval)
                                    )
                            )
                    )
            );

            SearchRequest request = new SearchRequest.Builder()
                    .index(Arrays.asList(indexes))
                    .query(Query.of(q -> q.bool(bool -> bool.filter(filterQueryList).mustNot(mustNotQueryList))))
                    .size(0)
                    .aggregations("aggs", agg -> agg
                            .composite(comp -> comp
                                    .size(conf.es_composite_bucket_size)
                                    .sources(compSources)
                            )
                            .aggregations("errSum", subAgg -> subAgg
                                    .sum(s -> s.field("errorHash"))
                            )
                    )
                    .ignoreUnavailable(true)
                    .allowNoIndices(true)
                    .expandWildcards(ExpandWildcard.Open)
                    .build();

            if (conf.print_es_query) {
                OpenSearchUtil.printJson(request);
            }

            OpenSearchClient client = Objects.requireNonNull(OpenSearchConnectionManager.getInstance()).getReadClient();

            boolean initialSearch = true;
            int bucketSize;
            List<XLogHistoVo> list = new ArrayList<>();
            Map<String, String> afterKey = null;

            do {
                if (!initialSearch) {
                    Map<String, String> finalAfterKey = afterKey;
                    request = new SearchRequest.Builder()
                            .index(Arrays.asList(indexes))
                            .query(Query.of(q -> q.bool(bool -> bool.filter(filterQueryList).mustNot(mustNotQueryList))))
                            .size(0)
                            .aggregations("aggs", agg -> agg
                                    .composite(comp -> comp
                                            .size(conf.es_composite_bucket_size)
                                            .sources(compSources)
                                            .after(finalAfterKey) // 첫 실행이 아니면 request 에 after 추가해서 조회
                                    )
                                    .aggregations("errSum", subAgg -> subAgg
                                            .sum(s -> s.field("errorHash"))
                                    )
                            )
                            .ignoreUnavailable(true)
                            .allowNoIndices(true)
                            .expandWildcards(ExpandWildcard.Open)
                            .build();
                } else {
                    initialSearch = false;
                }

                SearchResponse<Map> response = client.search(request, Map.class);
                CompositeAggregate composite = response.aggregations().get("aggs").composite();
                bucketSize = composite.buckets().array().size();

                for (CompositeBucket bucket : composite.buckets().array()) {
                    XLogHistoVo vo = new XLogHistoVo();
                    vo.time = ((Number) bucket.key().get("time")).longValue();
                    vo.elapsed = ((Number) bucket.key().get("elapsed")).intValue();
                    vo.count = bucket.docCount();
                    vo.error = bucket.aggregations().get("errSum").sum().value();
                    list.add(vo);
                }

                afterKey = composite.afterKey().entrySet().stream()
                        .collect(Collectors.toMap(Map.Entry::getKey, e -> e.getValue().toString()));
            } while (bucketSize > 0);

            if (list.isEmpty()) {
                return Collections.singletonMap("xlog", new ArrayList<>());
            }

            TreeMap<Long, HeatMapBucket[]> result = new XLogHistoMetering().process(list, histogramTimeInterval, args);

            List<Map<String, List<Integer>>> xlogList = new ArrayList<>();
            for (Map.Entry<Long, HeatMapBucket[]> entry : result.entrySet()) {
                Long time = entry.getKey();
                HeatMapBucket[] buckets = entry.getValue();
                List<Integer> innerList = new ArrayList<>();
                for (HeatMapBucket bucket : buckets) {
                    if (bucket.error) {
                        bucket.count = -bucket.count;
                    }
                    innerList.add(bucket.count);
                }
                xlogList.add(Collections.singletonMap(time.toString(), innerList));
            }

            //  RESULT PRINT
            Map<String, Object> resultMap = Collections.singletonMap("xlog", xlogList);
            if (conf.print_es_query_result) {
                resultMap.forEach((key, value) -> Logger.println(key + " : " + value));
            }

            System.out.println("EndUserTxOsch xlogList Size : " + xlogList.size());
            return resultMap;

        } catch (Exception e) {
            System.out.println(e.getMessage());
            throw e;
        }
    }

    @Override
    public List<Map<String, Object>> LoadEndUserTopNTransaction(TopTxSearchArgs args) throws Exception {
        try {
            List<String> timeList = DateUtil.getSearchRangeTime("enduser-info-", args.from, args.to);
            if (timeList == null) return new ArrayList<>();

            String[] indexes = timeList.toArray(new String[0]);

            List<Query> filterQueryList = new ArrayList<>();
            List<Query> mustQueryList = new ArrayList<>();
            List<Query> mustNotQueryList = new ArrayList<>();

            filterQueryList.add(
                    RangeQuery.of(r -> r
                            .field("endTime")
                            .gte(JsonData.of(args.from))
                            .lte(JsonData.of(args.to))
                    ).toQuery()
            );
            filterQueryList.add(
                    TermsQuery.of(t -> t
                            .field("objHash")
                            .terms(v -> v.value(OpenSearchUtil.getFieldValueList(args.objList)))
                    ).toQuery()
            );

            mustQueryList.add(
                    MatchQuery.of(m -> m
                            .field("type")
                            .query(FieldValue.of(E2ETypeConstants.DOCUMENT))
                    ).toQuery()
            );

            Map<String, Object> filters = args.fileterMap;
            for (String key : filters.keySet()) {
                if (key.equals("elapsed")) {
                    filterQueryList.add(
                            RangeQuery.of(r -> r
                                    .field("elapsedTime")
                                    .gte(JsonData.of(filters.get(key)))
                            ).toQuery()
                    );
                } else if (key.equals("error")) {
                    mustNotQueryList.add(
                            MatchQuery.of(m -> m
                                    .field("errorHash")
                                    .query(FieldValue.of(0))
                            ).toQuery()
                    );
                } else {
                    TermsQuery.of(t -> t
                            .field(key)
                            .terms(tqf -> tqf.value(OpenSearchUtil.getFieldValueList(filters.get(key))))
                    ).toQuery();
                }
            }

            if (args.serviceHash != 0L) {
                filterQueryList.add(
                        MatchQuery.of(m -> m
                                .field("serviceHash")
                                .query(FieldValue.of(args.serviceHash))
                        ).toQuery()
                );
            }
            mustNotQueryList.add(
                    MatchQuery.of(m -> m
                            .field("type")
                            .query(FieldValue.of(E2ETypeConstants.ERROR))
                    ).toQuery()
            );

            Aggregation aggregation = Aggregation.of(a -> a
                    .terms(t -> t
                            .field("serviceHash")
                            .size(args.top)
                            .shardSize(args.shard_size > 0 ? args.shard_size : null)
                            .order(Map.of("elapsedTimeStat.avg", SortOrder.Desc))
                    )
                    .aggregations(Map.of(
                            "elapsedTimeStat", Aggregation.of(a1 -> a1.extendedStats(s -> s.field("elapsedTime"))),
                            "timeToFirstByteRecvStat", Aggregation.of(a2 -> a2.extendedStats(s -> s.field("timeToFirstByteRecv"))),
                            "timeToDomCompleteStat", Aggregation.of(a3 -> a3.extendedStats(s -> s.field("timeToDomComplete"))),
                            "call", Aggregation.of(a4 -> a4.valueCount(v -> v.field("serviceHash")))
                    ))
            );

            SearchRequest request = new SearchRequest.Builder()
                    .index(Arrays.asList(indexes))
                    .query(Query.of(q -> q.bool(bool -> bool.filter(filterQueryList).must(mustQueryList).mustNot(mustNotQueryList))))
                    .size(0)
                    .aggregations("topN", aggregation)
                    .build();

            if (conf.print_es_query) {
                OpenSearchUtil.printJson(request);
            }

            OpenSearchClient client = Objects.requireNonNull(OpenSearchConnectionManager.getInstance()).getReadClient();

            SearchResponse<Map> response = client.search(request, Map.class);
            List<Map<String, Object>> result = new ArrayList<>();

            //  조회결과가 없는 경우 Empty List Return
            if (response.aggregations() == null || !response.aggregations().containsKey("topN")) {
                return result;
            }

            LongTermsAggregate lterms = response.aggregations().get("topN").lterms();
            for (LongTermsBucket bucket : lterms.buckets().array()) {
                ExtendedStatsAggregate elapsedTimeStat = bucket.aggregations().get("elapsedTimeStat").extendedStats();
                ExtendedStatsAggregate timeToFirstByteRecvStat = bucket.aggregations().get("timeToFirstByteRecvStat").extendedStats();
                ExtendedStatsAggregate timeToDomCompleteStat = bucket.aggregations().get("timeToDomCompleteStat").extendedStats();
                
                long hash = Long.valueOf(bucket.key());

                Map<String, Object> innerMap = new HashMap<>();
                innerMap.put("hash", hash);
                innerMap.put("name", TextRDFactory.getTextRD().getString(args.from, args.to, TextTypes.SERVICE, hash));
                innerMap.put("call", bucket.aggregations().get("call").valueCount().value());
                innerMap.put("maxElapsed", elapsedTimeStat.max());
                innerMap.put("minElapsed", elapsedTimeStat.min());
                innerMap.put("avgElapsed", elapsedTimeStat.avg());
                innerMap.put("devElapsed", elapsedTimeStat.stdDeviation());
                innerMap.put("maxFirstByte", timeToFirstByteRecvStat.max());
                innerMap.put("minFirstByte", timeToFirstByteRecvStat.min());
                innerMap.put("avgFirstByte", timeToFirstByteRecvStat.avg());
                innerMap.put("devFirstByte", timeToFirstByteRecvStat.stdDeviation());
                innerMap.put("maxDomComplete", timeToDomCompleteStat.max());
                innerMap.put("minDomComplete", timeToDomCompleteStat.min());
                innerMap.put("avgDomComplete", timeToDomCompleteStat.avg());
                innerMap.put("devDomComplete", timeToDomCompleteStat.stdDeviation());

                result.add(innerMap);
            }

            if (conf.print_es_query_result) {
                QueryUtil.print(result);
            }

            return result;
        } catch (Exception e) {
            throw new Exception(e);
        }
    }

    //  Composite Aggregation 을 이용한 Method
    //  비어있는 값을 0으로 채울 수 없음
    //  2019.07.19 : 비어있는 값을 채우기 위해 Term Aggregation 으로 대체
    @Override
    public Map<String, Object> LoadEndUserTimeHisto2(XLogInfoSearchArgs args) throws Exception {
        try {
            List<String> timeIndexList = DateUtil.getSearchRangeTime("enduser-info-", args.from, args.to);
            if (timeIndexList == null) return new HashMap<String, Object>();

            String[] indexes = timeIndexList.toArray(new String[timeIndexList.size()]);
            SearchRequest searchRequest = new SearchRequest.Builder()
                    .index(indexes)
                    .build();

            SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();

            QueryBuilder queryBuilder = QueryBuilders.boolQuery()
                    .filter(QueryBuilders.rangeQuery("endTime").gte(args.from).lte(args.to))
                    .filter(QueryBuilders.termsQuery("objHash", args.objList))
                    .filter(QueryBuilders.termsQuery("type", new ArrayList<Integer>(Arrays.asList(E2ETypeConstants.DOCUMENT, E2ETypeConstants.XHR))));

            if (args.serviceHash != 0L) {
                ((BoolQueryBuilder) queryBuilder).filter(QueryBuilders.matchQuery("serviceHash", args.serviceHash));
            }
            ((BoolQueryBuilder) queryBuilder).mustNot(QueryBuilders.matchQuery("type", E2ETypeConstants.ERROR));

            // 2. set composite aggregation.
            List<CompositeValuesSourceBuilder<?>> compositeValuesSourceBuilderList = new ArrayList<>();
            DateHistogramValuesSourceBuilder histogramValuesSourceBuilder = new DateHistogramValuesSourceBuilder("time");

            if ((args.to - args.from) > (DateUtil.MILLIS_PER_DAY * 28)) {
                histogramValuesSourceBuilder.dateHistogramInterval(DateHistogramInterval.hours(1));
            } else if ((args.to - args.from) > (DateUtil.MILLIS_PER_DAY * 2)) {
                histogramValuesSourceBuilder.dateHistogramInterval(DateHistogramInterval.minutes(30));
            } else if ((args.to - args.from) > DateUtil.MILLIS_PER_DAY) {
                histogramValuesSourceBuilder.dateHistogramInterval(DateHistogramInterval.minutes(10));
            } else if ((args.to - args.from) > (DateUtil.MILLIS_PER_HOUR * 6)) {
                histogramValuesSourceBuilder.dateHistogramInterval(DateHistogramInterval.minutes(5));
            } else {
                histogramValuesSourceBuilder.dateHistogramInterval(DateHistogramInterval.seconds(30));
            }

            // Time Aggregation
            histogramValuesSourceBuilder.field("endTime");
            compositeValuesSourceBuilderList.add(histogramValuesSourceBuilder);
            // Type Aggregation
            compositeValuesSourceBuilderList.add(new TermsValuesSourceBuilder("type").field("type").missingBucket(true));

            CompositeAggregationBuilder aggBuilder = AggregationBuilders.composite("groupby", compositeValuesSourceBuilderList);
            aggBuilder.subAggregation(AggregationBuilders.avg("elapsedTimeStat").field("elapsedTime")).size(conf.es_composite_bucket_size);
            aggBuilder.subAggregation(AggregationBuilders.avg("timeToFirstByteRecvStat").field("timeToFirstByteRecv")).size(conf.es_composite_bucket_size);
            aggBuilder.subAggregation(AggregationBuilders.avg("timeToDomCompleteStat").field("timeToDomComplete")).size(conf.es_composite_bucket_size);

            // 3. set query
            sourceBuilder.query(queryBuilder)
                    .fetchSource(false) // no source
                    .aggregation(aggBuilder)
                    .size(0);  // no hits

            if (conf.print_es_query) {
                Logger.println(sourceBuilder.toString());
            }

            searchRequest.source(sourceBuilder).indicesOptions(IndicesOptions.LENIENT_EXPAND_OPEN);
            OpenSearchClient client = OpenSearchConfig.createOpenSearchClient();
            boolean initialSearch = true;
            int bucketSize = 0;
            ParsedComposite parsedComposite = null;

            List<Long> pageTimeList = new ArrayList<>();
            List<Long> pageElapsedList = new ArrayList<>();
            List<Long> pageFirstByteList = new ArrayList<>();
            List<Long> pageDomCompleteList = new ArrayList<>();
            List<Long> xhrTimeList = new ArrayList<>();
            List<Long> xhrElapsedList = new ArrayList<>();
            List<Long> xhrFirstByteList = new ArrayList<>();

            do {
                if (!initialSearch) {
                    Map<String, Object> afterKey = parsedComposite.afterKey();
                    aggBuilder.aggregateAfter(afterKey);
                } else {
                    initialSearch = false;
                }
                SearchResponse searchResponse = client.search(searchRequest, RequestOptions.DEFAULT);
                Aggregations aggs = searchResponse.getAggregations();
                if (aggs == null) break;
                parsedComposite = aggs.get("groupby");

                List<ParsedComposite.ParsedBucket> bucketList = parsedComposite.getBuckets();
                bucketSize = bucketList.size();

                for (ParsedComposite.ParsedBucket bucket : bucketList) {
                    Long time = (Long) bucket.getKey().get("time");
                    int type = Integer.parseInt(bucket.getKey().get("type").toString());
                    Map<String, Aggregation> aggMap = bucket.getAggregations().getAsMap();
                    for (String key : aggMap.keySet()) {
                        Object obj = aggMap.get(key);
                        Long value = 0L;
                        if (type == 11) {
                            if (key.equals("elapsedTimeStat")) {
                                pageTimeList.add(time);
                                pageElapsedList.add((long) ((Avg) obj).getValue());
                            } else if (key.equals("timeToFirstByteRecvStat")) {
                                pageFirstByteList.add((long) ((Avg) obj).getValue());
                            } else if (key.equals("timeToDomCompleteStat")) {
                                pageDomCompleteList.add((long) ((Avg) obj).getValue());
                            }
                        } else if (type == 5) {
                            if (key.equals("elapsedTimeStat")) {
                                xhrTimeList.add(time);
                                xhrElapsedList.add((long) ((Avg) obj).getValue());
                            } else if (key.equals("timeToFirstByteRecvStat")) {
                                xhrFirstByteList.add((long) ((Avg) obj).getValue());
                            }
                        }
                    }
                }
            } while (bucketSize > 0);

            Map<String, Object> pageMap = new HashMap<>();
            pageMap.put("time", pageTimeList);
            pageMap.put("elapsedTimeStat", pageElapsedList);
            pageMap.put("timeToFirstByteRecvStat", pageFirstByteList);
            pageMap.put("timeToDomCompleteStat", pageDomCompleteList);

            Map<String, Object> xhrMap = new HashMap<>();
            xhrMap.put("time", xhrTimeList);
            xhrMap.put("elapsedTimeStat", xhrElapsedList);
            xhrMap.put("timeToFirstByteRecvStat", xhrFirstByteList);

            Map<String, Object> result = new HashMap<>();
            result.put("page", pageMap);
            result.put("xhr", xhrMap);

            if (conf.print_es_query_result) {
                QueryUtil.print(result);
            }
            return result;

        } catch (Exception ex) {
            System.out.println(ex.getMessage());
            throw ex;
        }
    }

    @Override
    public Map<String, Object> LoadEndUserTimeHisto(XLogInfoSearchArgs args) throws Exception {
        try {
            List<String> timeIndexList = DateUtil.getSearchRangeTime("enduser-info-", args.from, args.to);
            if (timeIndexList == null) return new HashMap<String, Object>();

            String[] indexes = timeIndexList.toArray(new String[timeIndexList.size()]);
            SearchRequest searchRequest = new SearchRequest.Builder()
                    .index(indexes)
                    .build();

            SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();

            QueryBuilder queryBuilder = QueryBuilders.boolQuery()
                    .filter(QueryBuilders.rangeQuery("endTime").gte(args.from).lte(args.to))
                    .filter(QueryBuilders.termsQuery("objHash", args.objList))
                    .filter(QueryBuilders.termsQuery("type", new ArrayList<Integer>(Arrays.asList(E2ETypeConstants.DOCUMENT, E2ETypeConstants.XHR))));

            if (args.serviceHash != 0L) {
                ((BoolQueryBuilder) queryBuilder).filter(QueryBuilders.matchQuery("serviceHash", args.serviceHash));
            }
            ((BoolQueryBuilder) queryBuilder).mustNot(QueryBuilders.matchQuery("type", E2ETypeConstants.ERROR));

            Map<String, Object> filters = args.fileterMap;
            for (String key : filters.keySet()) {
                if (key.equals("elapsed")) {
                    ((BoolQueryBuilder) queryBuilder).filter(QueryBuilders.rangeQuery("elapsedTime").gte(filters.get(key)));
                } else if (key.equals("error")) {
                    ((BoolQueryBuilder) queryBuilder).mustNot(QueryBuilders.matchQuery("errorHash", 0));
                } else {
                    ((BoolQueryBuilder) queryBuilder).filter(QueryBuilders.termsQuery(key, filters.get(key)));
                }
            }

            DateHistogramAggregationBuilder histogramBuilder = AggregationBuilders.dateHistogram("time")
                    .dateHistogramInterval(new DateHistogramIntervalManager().getHistogramInterval(args.from, args.to))
                    .field("endTime")
                    .extendedBounds(new ExtendedBounds(args.from, args.to))
                    .minDocCount(0);

            TermsAggregationBuilder termsAggregationBuilder = AggregationBuilders.terms("groupby")
                    .field("type")
                    .minDocCount(0);
            if (args.shardSize > 0) {
                termsAggregationBuilder.shardSize(args.shardSize);
            }
            termsAggregationBuilder.subAggregation(AggregationBuilders.avg("avg_elapsed").field("elapsedTime"));
            termsAggregationBuilder.subAggregation(AggregationBuilders.avg("avg_firstnet").field("timeToFirstByteRecv"));
            termsAggregationBuilder.subAggregation(AggregationBuilders.avg("avg_dom").field("timeToDomComplete"));
            histogramBuilder.subAggregation(termsAggregationBuilder);

            sourceBuilder.query(queryBuilder)
                    .fetchSource(false)
                    .aggregation(histogramBuilder)
                    .size(0)
                    .timeout(new TimeValue(60, TimeUnit.SECONDS));

            if (conf.print_es_query) {
                Logger.println(sourceBuilder.toString());
            }

            searchRequest.source(sourceBuilder)
                    .indicesOptions(IndicesOptions.LENIENT_EXPAND_OPEN);

            OpenSearchClient client = OpenSearchConnectionManager.getInstance().getReadClient();

            SearchResponse searchResponse = client.search(searchRequest, RequestOptions.DEFAULT);

            List<Long> pageTimeList = new ArrayList<Long>();
            List<Long> pageElapsedList = new ArrayList<Long>();
            List<Long> pageFirstByteList = new ArrayList<Long>();
            List<Long> pageDomCompleteList = new ArrayList<Long>();
            List<Long> xhrTimeList = new ArrayList<Long>();
            List<Long> xhrElapsedList = new ArrayList<Long>();
            List<Long> xhrFirstByteList = new ArrayList<Long>();

            Map<String, Object> result = new HashMap<String, Object>();

            if (searchResponse.getAggregations() == null) return result;
            if (!searchResponse.getAggregations().getAsMap().containsKey("time")) return result;

            ParsedDateHistogram pdh = (ParsedDateHistogram) searchResponse.getAggregations().getAsMap().get("time");
            List<ParsedDateHistogram.ParsedBucket> bucketList = (List<ParsedDateHistogram.ParsedBucket>) pdh.getBuckets();

            for (ParsedDateHistogram.ParsedBucket bucket : bucketList) {
                Long time = Long.parseLong(bucket.getKeyAsString());

                Terms terms = bucket.getAggregations().get("groupby");
                List<ParsedTerms.ParsedBucket> innerBucketList = (List<ParsedTerms.ParsedBucket>) terms.getBuckets();

                if (innerBucketList.size() == 0) {
                    pageTimeList.add(time);
                    pageElapsedList.add(0L);
                    pageFirstByteList.add(0L);
                    pageDomCompleteList.add(0L);
                    xhrTimeList.add(time);
                    xhrElapsedList.add(0L);
                    xhrFirstByteList.add(0L);
                } else if (innerBucketList.size() == 1) {
                    if (innerBucketList.get(0).getKeyAsString().equals("11")) {
                        xhrTimeList.add(time);
                        xhrElapsedList.add(0L);
                        xhrFirstByteList.add(0L);
                    } else if (innerBucketList.get(0).getKeyAsString().equals("5")) {
                        pageTimeList.add(time);
                        pageElapsedList.add(0L);
                        pageFirstByteList.add(0L);
                        pageDomCompleteList.add(0L);
                    }
                }

                for (ParsedTerms.ParsedBucket innerBucket : innerBucketList) {
                    int type = Integer.parseInt(innerBucket.getKeyAsString());
                    Map<String, Aggregation> aggMap = innerBucket.getAggregations().getAsMap();
                    for (String key : aggMap.keySet()) {
                        Object obj = aggMap.get(key);
                        Double d = ((Avg) obj).getValue();
                        Long value = Double.isInfinite(d) ? 0L : d.longValue();

                        if (type == 11) {
                            if (key.equals("avg_elapsed")) {
                                pageTimeList.add(time);
                                pageElapsedList.add(value);
                            } else if (key.equals("avg_firstnet")) {
                                pageFirstByteList.add(value);
                            } else if (key.equals("avg_dom")) {
                                pageDomCompleteList.add(value);
                            }
                        } else if (type == 5) {
                            if (key.equals("avg_elapsed")) {
                                xhrTimeList.add(time);
                                xhrElapsedList.add(value);
                            } else if (key.equals("avg_firstnet")) {
                                xhrFirstByteList.add(value);
                            }
                        }
                    }
                }
            }

            Map<String, Object> pageMap = new HashMap<String, Object>();
            pageMap.put("time", pageTimeList);
            pageMap.put("elapsedTimeStat", pageElapsedList);
            pageMap.put("timeToFirstByteRecvStat", pageFirstByteList);
            pageMap.put("timeToDomCompleteStat", pageDomCompleteList);

            Map<String, Object> xhrMap = new HashMap<String, Object>();
            xhrMap.put("time", xhrTimeList);
            xhrMap.put("elapsedTimeStat", xhrElapsedList);
            xhrMap.put("timeToFirstByteRecvStat", xhrFirstByteList);

            result.put("page", pageMap);
            result.put("xhr", xhrMap);

            if (conf.print_es_query_result) {
                QueryUtil.print(result);
            }
            return result;

        } catch (Exception ex) {
            System.out.println(ex.getMessage());
            throw ex;
        }

        @Override
        public Map<Long, Map<String, List<Long>>> LoadEndUserTimeHistoByInstance(XLogInfoSearchArgs args) throws Exception {
            try {
                List<String> timeIndexList = DateUtil.getSearchRangeTime("enduser-info-", args.from, args.to);
                if (timeIndexList == null) return new HashMap<Long, Map<String, List<Long>>>();

                String[] indexes = timeIndexList.toArray(new String[timeIndexList.size()]);
                SearchRequest searchRequest = new SearchRequest(indexes);
                SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();

                QueryBuilder queryBuilder = QueryBuilders.boolQuery()
                        .filter(QueryBuilders.rangeQuery("endTime").gte(args.from).lte(args.to))
                        .filter(QueryBuilders.termsQuery("objHash", args.objList))
                        .filter(QueryBuilders.matchQuery("type", args.type));

                if (args.serviceHash != 0L) {
                    ((BoolQueryBuilder) queryBuilder).filter(QueryBuilders.matchQuery("serviceHash", args.serviceHash));
                }
                ((BoolQueryBuilder) queryBuilder).mustNot(QueryBuilders.matchQuery("type", E2ETypeConstants.ERROR));

                DateHistogramAggregationBuilder histogramBuilder = new DateHistogramAggregationBuilder("time");
                histogramBuilder.dateHistogramInterval(new DateHistogramIntervalManager().getHistogramInterval(args.from, args.to));
                histogramBuilder.field("endTime").extendedBounds(new ExtendedBounds(args.from, args.to));
                histogramBuilder.minDocCount(0);

                histogramBuilder.subAggregation(AggregationBuilders.avg("elapsedTimeStat").field("elapsedTime"));
                histogramBuilder.subAggregation(AggregationBuilders.avg("timeToFirstByteRecvStat").field("timeToFirstByteRecv"));
                histogramBuilder.subAggregation(AggregationBuilders.avg("timeToDomCompleteStat").field("timeToDomComplete"));

                sourceBuilder.query(queryBuilder)
                        .fetchSource(false)
                        .aggregation(histogramBuilder)
                        .size(0)
                        .timeout(new TimeValue(60, TimeUnit.SECONDS));

                if (conf.print_es_query) {
                    Logger.println(sourceBuilder.toString());
                }

                searchRequest.source(sourceBuilder).indicesOptions(IndicesOptions.LENIENT_EXPAND_OPEN);
                OpenSearchClient client = OpenSearchConnectionManager.getInstance().getReadClient(); // OpenSearchClient 사용
                SearchResponse searchResponse = client.search(searchRequest, RequestOptions.DEFAULT);

                Map<Long, Map<String, List<Long>>> result = new HashMap<Long, Map<String, List<Long>>>();

                if (searchResponse.getAggregations() == null) return result;
                if (!searchResponse.getAggregations().getAsMap().containsKey("time")) return result;

                ParsedDateHistogram pdh = (ParsedDateHistogram) searchResponse.getAggregations().getAsMap().get("time");
                List<ParsedDateHistogram.ParsedBucket> bucketList = (List<ParsedDateHistogram.ParsedBucket>) pdh.getBuckets();

                Map<String, List<Long>> innerMap = new HashMap<String, List<Long>>();
                innerMap.put("time", new ArrayList<Long>());
                innerMap.put("elapsedTime", new ArrayList<Long>());
                innerMap.put("timeToFirstByteRecv", new ArrayList<Long>());
                if (args.type == Byte.valueOf("11")) innerMap.put("timeToDomComplete", new ArrayList<Long>());

                for (ParsedDateHistogram.ParsedBucket bucket : bucketList) {
                    Long time = Long.parseLong(bucket.getKeyAsString());
                    innerMap.get("time").add(time);
                    if (bucket.getAggregations().getAsMap().size() == 0) System.out.println("Empty Map");
                    Map<String, Aggregation> aggMap = bucket.getAggregations().getAsMap();
                    for (String key : aggMap.keySet()) {
                        Object obj = aggMap.get(key);
                        Double d = ((Avg) obj).getValue();
                        Long value = Double.isInfinite(d) ? 0L : d.longValue();

                        if (key.equals("elapsedTimeStat")) {
                            innerMap.get("elapsedTime").add(value);
                        } else if (key.equals("timeToFirstByteRecvStat")) {
                            innerMap.get("timeToFirstByteRecv").add(value);
                        } else if (key.equals("timeToDomCompleteStat") && args.type == Byte.valueOf("11")) {
                            innerMap.get("timeToDomComplete").add(value);
                        }
                    }
                }

                result.put(Long.parseLong(args.objList.get(0).toString()), innerMap);

                if (conf.print_es_query_result) {
                    QueryUtil.print(result);
                }
                return result;

            } catch (Exception ex) {
                System.out.println(ex.getMessage());
                throw ex;
            }


            private NumberFormat getNumberFormat(){
                NumberFormat nf = NumberFormat.getInstance();
                nf.setGroupingUsed(false);
                nf.setMaximumFractionDigits(3);
                return nf;
            }
        }
